{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb94108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset sizes: 1000 positives: 200 pos_rate: 0.2\n"
     ]
    }
   ],
   "source": [
    "# ============ Option A: Class-aware downsample ============\n",
    "\n",
    "import os, random, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths (adjust as needed)\n",
    "CSV_PATH = r\"C:/Users/chait/Downloads/melanoma_classification/data/train.csv\"\n",
    "IMG_DIR  = Path(r\"C:/Users/chait/Downloads/melanoma_classification/data/jpeg/train\")\n",
    "\n",
    "assert os.path.isfile(CSV_PATH), f\"CSV not found: {CSV_PATH}\"\n",
    "assert IMG_DIR.exists(), f\"Image directory not found: {IMG_DIR}\"\n",
    "\n",
    "# Load full training CSV\n",
    "df = pd.read_csv(CSV_PATH, low_memory=False)\n",
    "\n",
    "# Class-aware subset\n",
    "N_TOTAL = 1000  # set desired total rows in subset\n",
    "pos_df = df[df[\"target\"] == 1].copy()\n",
    "neg_df = df[df[\"target\"] == 0].copy()\n",
    "\n",
    "# Aim for ~20% positives in the subset if available; adjust as desired\n",
    "n_pos = min(len(pos_df), max(1, int(0.2 * N_TOTAL)))\n",
    "n_neg = min(len(neg_df), N_TOTAL - n_pos)\n",
    "\n",
    "pos_s = pos_df.sample(n=n_pos, random_state=42) if n_pos > 0 else pos_df.head(0)\n",
    "neg_s = neg_df.sample(n=n_neg, random_state=42) if n_neg > 0 else neg_df.head(0)\n",
    "df = pd.concat([pos_s, neg_s], axis=0).sample(frac=1.0, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(\"Subset sizes:\", len(df), \"positives:\", int(df['target'].sum()), \"pos_rate:\", df['target'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4031ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "META_DIM: 11\n"
     ]
    }
   ],
   "source": [
    "# ============ Preprocess metadata and build features ============\n",
    "\n",
    "# Fill missing metadata\n",
    "df[\"sex\"] = df[\"sex\"].fillna(\"Unknown\")\n",
    "df[\"anatom_site_general_challenge\"] = df[\"anatom_site_general_challenge\"].fillna(\"Unknown\")\n",
    "df[\"age_approx\"] = df[\"age_approx\"].fillna(df[\"age_approx\"].median())\n",
    "\n",
    "# Build vocab from subset\n",
    "cat_cols = [\"sex\", \"anatom_site_general_challenge\"]\n",
    "cat_vocab = {}\n",
    "for c in cat_cols:\n",
    "    cats = sorted(df[c].astype(str).unique().tolist())\n",
    "    cat_vocab[c] = {v: i for i, v in enumerate(cats)}\n",
    "\n",
    "def build_meta_features(ddf: pd.DataFrame) -> np.ndarray:\n",
    "    sex_idx  = ddf[\"sex\"].astype(str).map(cat_vocab[\"sex\"]).astype(int).values\n",
    "    site_idx = ddf[\"anatom_site_general_challenge\"].astype(str).map(cat_vocab[\"anatom_site_general_challenge\"]).astype(int).values\n",
    "    sex_oh  = np.eye(len(cat_vocab[\"sex\"]), dtype=np.float32)[sex_idx]\n",
    "    site_oh = np.eye(len(cat_vocab[\"anatom_site_general_challenge\"]), dtype=np.float32)[site_idx]\n",
    "    age = np.clip(ddf[\"age_approx\"].values.astype(np.float32) / 100.0, 0.0, 1.0).reshape(-1, 1)\n",
    "    return np.concatenate([age, sex_oh, site_oh], axis=1).astype(np.float32)\n",
    "\n",
    "meta = build_meta_features(df)\n",
    "META_DIM = meta.shape[1]\n",
    "print(\"META_DIM:\", META_DIM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e73851e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold sizes (images):\n",
      " fold\n",
      "0    197\n",
      "1    203\n",
      "2    192\n",
      "3    212\n",
      "4    196\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============ Patient-grouped stratified folds ============\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "assert \"patient_id\" in df.columns and \"target\" in df.columns, \"CSV must include patient_id and target.\"\n",
    "\n",
    "pt = df.groupby(\"patient_id\").agg(n=(\"image_name\", \"count\"), y=(\"target\", \"max\")).reset_index()\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "pt[\"fold\"] = -1\n",
    "for fold, (_, val_idx) in enumerate(skf.split(pt, pt[\"y\"])):\n",
    "    pt.loc[val_idx, \"fold\"] = fold\n",
    "\n",
    "df = df.merge(pt[[\"patient_id\", \"fold\"]], on=\"patient_id\", how=\"left\")\n",
    "print(\"Fold sizes (images):\\n\", df[\"fold\"].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "056c1edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chait\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shapes: (8, 3, 320, 320) (8, 11) (8,)\n"
     ]
    }
   ],
   "source": [
    "# ============ Transforms and Dataset (light, fast) ============\n",
    "\n",
    "import cv2, albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "IMG_SIZE = 320  # smaller for speed\n",
    "MEAN, STD = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "\n",
    "train_tfms = A.Compose([\n",
    "    A.Resize(height=IMG_SIZE, width=IMG_SIZE, interpolation=cv2.INTER_CUBIC),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Normalize(mean=MEAN, std=STD),\n",
    "    ToTensorV2()\n",
    "])\n",
    "valid_tfms = A.Compose([\n",
    "    A.Resize(height=IMG_SIZE, width=IMG_SIZE, interpolation=cv2.INTER_CUBIC),\n",
    "    A.Normalize(mean=MEAN, std=STD),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "class MelanomaDataset(Dataset):\n",
    "    def __init__(self, df_in, img_dir, meta_array, tfms):\n",
    "        self.df = df_in.reset_index(drop=True)\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.meta = meta_array\n",
    "        self.tfms = tfms\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        r = self.df.iloc[idx]\n",
    "        p = self.img_dir / f\"{r.image_name}.jpg\"\n",
    "        img = cv2.imread(str(p))\n",
    "        if img is None:\n",
    "            img = np.zeros((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        x = self.tfms(image=img)[\"image\"]\n",
    "        m = torch.tensor(self.meta[idx], dtype=torch.float32)\n",
    "        y = torch.tensor(float(r.target), dtype=torch.float32)\n",
    "        return x, m, y\n",
    "\n",
    "def make_loaders_for_fold_quick(fold, batch_size=8):\n",
    "    arr = df[\"fold\"].values\n",
    "    trn_idx = np.where(arr != fold)[0]\n",
    "    val_idx = np.where(arr == fold)\n",
    "    dtr, dva = df.iloc[trn_idx], df.iloc[val_idx]\n",
    "    mtr, mva = meta[trn_idx], meta[val_idx]\n",
    "\n",
    "    train_ds = MelanomaDataset(dtr, IMG_DIR, mtr, train_tfms)\n",
    "    valid_ds = MelanomaDataset(dva, IMG_DIR, mva, valid_tfms)\n",
    "\n",
    "    # Windows-safe: num_workers=0, pin_memory=False\n",
    "    tl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=False)\n",
    "    vl = DataLoader(valid_ds, batch_size=batch_size*2, shuffle=False, num_workers=0, pin_memory=False)\n",
    "    return tl, vl, trn_idx, val_idx\n",
    "\n",
    "# Smoke test\n",
    "tl, vl, tri, vai = make_loaders_for_fold_quick(fold=int(df[\"fold\"].unique()[0]), batch_size=8)\n",
    "xb, mb, yb = next(iter(tl))\n",
    "print(\"Batch shapes:\", tuple(xb.shape), tuple(mb.shape), tuple(yb.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60cc4109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Meta] ep 0 AUC 0.7293 | AP 0.4017\n",
      "[Meta] ep 1 AUC 0.7091 | AP 0.4445\n",
      "[Meta] Fold 0 best AUC: 0.7293\n"
     ]
    }
   ],
   "source": [
    "# ============ Metadata-only quick baseline ============\n",
    "\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def roc_pr(y_true, y_prob):\n",
    "    return roc_auc_score(y_true, y_prob), average_precision_score(y_true, y_prob)\n",
    "\n",
    "def pos_weight_from_labels(y):\n",
    "    y = y.astype(np.float32)\n",
    "    pos = y.sum()\n",
    "    neg = len(y) - pos\n",
    "    return float(np.sqrt((neg + 1e-6) / (pos + 1e-6)))\n",
    "\n",
    "class MetaMLP(nn.Module):\n",
    "    def __init__(self, dim_in):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim_in, 64), nn.ReLU(True), nn.BatchNorm1d(64), nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32), nn.ReLU(True), nn.BatchNorm1d(32), nn.Dropout(0.1),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    def forward(self, m):\n",
    "        return self.net(m).squeeze(1)\n",
    "\n",
    "def train_meta_once(train_loader, valid_loader, epochs=2, lr=1e-3, pos_weight=1.0):\n",
    "    model = MetaMLP(META_DIM).to(DEVICE)\n",
    "    opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight], device=DEVICE))\n",
    "    best_auc, best_p, best_y = -1, None, None\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        for _, mb, yb in train_loader:\n",
    "            mb, yb = mb.to(DEVICE), yb.to(DEVICE)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            loss = bce(model(mb), yb)\n",
    "            loss.backward(); opt.step()\n",
    "        model.eval(); probs=[]; ys=[]\n",
    "        with torch.no_grad():\n",
    "            for _, mva, yva in valid_loader:\n",
    "                p = torch.sigmoid(model(mva.to(DEVICE))).cpu().numpy()\n",
    "                probs.append(p); ys.append(yva.numpy())\n",
    "        y = np.concatenate(ys); p = np.concatenate(probs)\n",
    "        auc, ap = roc_pr(y, p)\n",
    "        best_auc, best_p, best_y = (auc, p, y) if auc > best_auc else (best_auc, best_p, best_y)\n",
    "        print(f\"[Meta] ep {ep} AUC {auc:.4f} | AP {ap:.4f}\")\n",
    "    return best_auc, best_y, best_p\n",
    "\n",
    "# Run on a single fold for speed\n",
    "FOLD = int(df[\"fold\"].unique()[0])\n",
    "train_loader, valid_loader, trn_idx, val_idx = make_loaders_for_fold_quick(FOLD, batch_size=8)\n",
    "pos_w = pos_weight_from_labels(df.iloc[trn_idx][\"target\"].values)\n",
    "best_auc_meta, yv_m, pv_m = train_meta_once(train_loader, valid_loader, epochs=2, lr=1e-3, pos_weight=pos_w)\n",
    "print(f\"[Meta] Fold {FOLD} best AUC: {best_auc_meta:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b7e82e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chait\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\chait\\.cache\\huggingface\\hub\\models--timm--tf_efficientnet_b0.ns_jft_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\chait\\AppData\\Local\\Temp\\ipykernel_32360\\620824400.py:30: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "C:\\Users\\chait\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\amp\\grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n",
      "C:\\Users\\chait\\AppData\\Local\\Temp\\ipykernel_32360\\620824400.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\chait\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\amp\\autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Img+Meta b0] ep 0 AUC 0.9168 | AP 0.7584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chait\\AppData\\Local\\Temp\\ipykernel_32360\\620824400.py:37: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "C:\\Users\\chait\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\amp\\autocast_mode.py:265: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Img+Meta b0] ep 1 AUC 0.8637 | AP 0.6755\n",
      "[Img+Meta b0] Fold 0 best AUC: 0.9168\n"
     ]
    }
   ],
   "source": [
    "# ============ Image+metadata quick model ============\n",
    "\n",
    "# If timm is not available, test with a tiny CNN first (comment block below).\n",
    "USE_EFFICIENTNET = True\n",
    "\n",
    "if USE_EFFICIENTNET:\n",
    "    import timm\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "    class ImgMetaModel(nn.Module):\n",
    "        def __init__(self, backbone=\"tf_efficientnet_b0\", meta_dim=META_DIM, dropout=0.2, pretrained=True):\n",
    "            super().__init__()\n",
    "            self.backbone = timm.create_model(backbone, pretrained=pretrained, num_classes=0, global_pool=\"avg\")\n",
    "            feat_dim = self.backbone.num_features\n",
    "            self.img_do = nn.Dropout(dropout)\n",
    "            self.meta = nn.Sequential(\n",
    "                nn.Linear(meta_dim, 64), nn.ReLU(True), nn.BatchNorm1d(64), nn.Dropout(0.1),\n",
    "                nn.Linear(64, 32), nn.ReLU(True)\n",
    "            )\n",
    "            self.head = nn.Sequential(nn.Linear(feat_dim + 32, 1))\n",
    "        def forward(self, x, m):\n",
    "            f = self.img_do(self.backbone(x))\n",
    "            g = self.meta(m)\n",
    "            return self.head(torch.cat([f, g], dim=1)).squeeze(1)\n",
    "\n",
    "    def train_img_once(train_loader, valid_loader, epochs=2, lr=3e-4, pos_weight=1.0, backbone=\"tf_efficientnet_b0\"):\n",
    "        model = ImgMetaModel(backbone=backbone, meta_dim=META_DIM, pretrained=True).to(DEVICE)\n",
    "        opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "        bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight], device=DEVICE))\n",
    "        scaler = GradScaler()\n",
    "        best_auc, best_p, best_y = -1, None, None\n",
    "        for ep in range(epochs):\n",
    "            model.train()\n",
    "            for xb, mb, yb in train_loader:\n",
    "                xb, mb, yb = xb.to(DEVICE), mb.to(DEVICE), yb.to(DEVICE)\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                with autocast():\n",
    "                    loss = bce(model(xb, mb), yb)\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(opt); scaler.update()\n",
    "            model.eval(); probs=[]; ys=[]\n",
    "            with torch.no_grad():\n",
    "                for xb, mb, yb in valid_loader:\n",
    "                    p = torch.sigmoid(model(xb.to(DEVICE), mb.to(DEVICE))).cpu().numpy()\n",
    "                    probs.append(p); ys.append(yb.numpy())\n",
    "            y = np.concatenate(ys); p = np.concatenate(probs)\n",
    "            auc, ap = roc_pr(y, p)\n",
    "            best_auc, best_p, best_y = (auc, p, y) if auc > best_auc else (best_auc, best_p, best_y)\n",
    "            print(f\"[Img+Meta b0] ep {ep} AUC {auc:.4f} | AP {ap:.4f}\")\n",
    "        return best_auc, best_y, best_p\n",
    "\n",
    "    best_auc_img, yv_i, pv_i = train_img_once(train_loader, valid_loader, epochs=2, lr=3e-4, pos_weight=pos_w, backbone=\"tf_efficientnet_b0\")\n",
    "    print(f\"[Img+Meta b0] Fold {FOLD} best AUC: {best_auc_img:.4f}\")\n",
    "\n",
    "else:\n",
    "    # Tiny fallback if timm not available\n",
    "    class TinyCNN(nn.Module):\n",
    "        def __init__(self, meta_dim):\n",
    "            super().__init__()\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(True), nn.MaxPool2d(2),\n",
    "                nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(True), nn.AdaptiveAvgPool2d(1)\n",
    "            )\n",
    "            self.meta = nn.Sequential(nn.Linear(meta_dim, 32), nn.ReLU(True))\n",
    "            self.head = nn.Linear(32 + 32, 1)\n",
    "        def forward(self, x, m):\n",
    "            f = self.conv(x).flatten(1)\n",
    "            g = self.meta(m)\n",
    "            return self.head(torch.cat([f, g], dim=1)).squeeze(1)\n",
    "\n",
    "    def train_tiny_once(train_loader, valid_loader, epochs=2, lr=1e-3, pos_weight=1.0):\n",
    "        model = TinyCNN(META_DIM).to(DEVICE)\n",
    "        opt = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "        bce = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight], device=DEVICE))\n",
    "        best_auc, best_p, best_y = -1, None, None\n",
    "        for ep in range(epochs):\n",
    "            model.train()\n",
    "            for xb, mb, yb in train_loader:\n",
    "                xb, mb, yb = xb.to(DEVICE), mb.to(DEVICE), yb.to(DEVICE)\n",
    "                opt.zero_grad(set_to_none=True)\n",
    "                loss = bce(model(xb, mb), yb)\n",
    "                loss.backward(); opt.step()\n",
    "            model.eval(); probs=[]; ys=[]\n",
    "            with torch.no_grad():\n",
    "                for xb, mb, yb in valid_loader:\n",
    "                    p = torch.sigmoid(model(xb.to(DEVICE), mb.to(DEVICE))).cpu().numpy()\n",
    "                    probs.append(p); ys.append(yb.numpy())\n",
    "            y = np.concatenate(ys); p = np.concatenate(probs)\n",
    "            auc, ap = roc_pr(y, p)\n",
    "            best_auc, best_p, best_y = (auc, p, y) if auc > best_auc else (best_auc, best_p, best_y)\n",
    "            print(f\"[Img+Meta Tiny] ep {ep} AUC {auc:.4f} | AP {ap:.4f}\")\n",
    "        return best_auc, best_y, best_p\n",
    "\n",
    "    best_auc_img, yv_i, pv_i = train_tiny_once(train_loader, valid_loader, epochs=2, lr=1e-3, pos_weight=pos_w)\n",
    "    print(f\"[Img+Meta Tiny] Fold {FOLD} best AUC: {best_auc_img:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
